1. We can continue to exclude stopwords during indexing, and
then treat stopwords as 'invisible' words during search. For
example, when searching "national university of singapore", the
search would instead be for:

("national",x) AND ("university",x+1) AND ("singapore",x+3)

Where x is the positon for the term "national" within the
document.

This way, no extra space would be used, and results are
_likely_ to be relevant. This would be a cost saving compared to
indexing all of the stopwords just to enable using stopwords in
phrasal queries.

2. My implementation of dictionary as a string uses pointers
written in plain text. Many of these are longer than 4 bytes and
as such, the resulting size of the "compressed" dictionary is
larger than the original. Here are the original values of the 
dictionary.txt files in bytes.

Before "compression"	After "compression"
510225					691801

Since each of the files have 28073 entries, and there are 172727
characters in the dictionary as a string, then there are an
average of 6.152 characters per word. This means that, assuming
we use 4 bytes per pointer, we can arrive at the actual
compressed size of the dictionary from the original by:

	 Original Size + No. of Lines * (4 - 6.152)

This would give us about 449809.752 as the new size of the
dictionary. Using these estimates, we can comeup with a table of
estimated dictionary sizes given different types of compression:


							Size		delta %		T%
(a) Original				510225		
(b) Dictionary as String	449810		11.8		11.8
(c) Blocking				365571		18.7		28.4

Here, the size of the dictionary using blocking was computed by
subtracting the size of all the terms put together (172727) by
the size of the original dictionary (510225), and then adding
the size of new pointers: multiplying the number of entries
with pointers (floor(28073/4)), by 4. This gives 365571.

3. Having already implemented a prefix tree for the
dictionary, I would traverse down the dictionary with the
characters a,u,t,o,m,a,t. An 'OR' operation between the 
leaves of this sub-tree would then give us our result.

4. I would have to enumerate through every item in the hash and
check if the item begins with "automat". Using a prefix tree
would be a more efficient search strategy, since using a hash
table would require linear time in the dictionary size, while
using a prefix tree, the lookup will be linear in the size of
the search string.

I would not recommend this data structure over a tree
implementation.
